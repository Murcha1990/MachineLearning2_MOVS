{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это домашнее задание состоит из двух частей, и весит в 1.5 раза больше, чем предыдущие домашние задания. То есть за задание можно получить 15 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Часть 1. Бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг своими руками (4 балла)\n",
    "\n",
    "Реализуйте алгоритм градиентного бустинга для регрессии. Напомним основные формулы.\n",
    "\n",
    "Обозначим текущую композицию на $N-1$ шаге за $a_{N - 1}(x_i)$. Следующий базовый алгоритм $b_N(x_i)$ обучается на ответах $-\\frac{\\partial L(y_i, z)}{\\partial z}\\Bigl|_{z = a_{N - 1}(x_i)}$, где $L(y_i, z)$ — значение функции потерь на объекте при правильном ответе $y_i$ и предсказании $z$. Композиция на следующем шаге получается следующим образом:\n",
    "\n",
    "$$\n",
    "a_N(x_i) = a_{N-1}(x_i) + \\nu\\gamma_Nb_N(x_i)\n",
    "$$\n",
    "\n",
    "Здесь $\\nu$ — гиперпараметр learning rate, $\\gamma_N$ — оптимальный вес, настраиваемый на каждом шаге алгоритма, который можно найти по следующей формуле (обратите внимание на отсутствие $\\nu$):\n",
    "\n",
    "$$\n",
    "\\gamma_N = \\mathrm{arg}\\min_\\gamma \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}L\\left(y_i, a_{N - 1}(x_i) + \\gamma b_N(x_i)\\right)\n",
    "$$\n",
    "\n",
    "Можете принять $\\gamma_N = 1$ для каждого $N$. Реализуйте нахождение оптимального $\\gamma_N$ на каждом шаге, чтобы получить ещё 1 балл.\n",
    "\n",
    "В качестве функции потерь возьмите MSE.\n",
    "\n",
    "*Примечание. Вы можете использовать `DecisionTree` из `sklearn` и методы оптимизации из различных библиотек.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это может помочь вам для поиска оптимальных gamma\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators, max_depth, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        n_estimators - number of trees in the ensemble\n",
    "        max_depth - maximum depth of a tree\n",
    "        learning_rate - coefficient by which new algorithm result is multiplied\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        x - np.array of shape (k, d)\n",
    "        y - np.array of shape (k,)\n",
    "        \"\"\"\n",
    "        # Здесь нам нужно проитерироваться по n_estimators и обучить\n",
    "        # соответствующее количество деревьев с помощью _fit_predict_tree(),\n",
    "        # правильно обновляя y_new\n",
    "        # Деревья нужно где-то сохранить, чтобы затем использовать в predict()\n",
    "        # your code here\n",
    "        for ...:\n",
    "            y_new = ...\n",
    "            # your code here\n",
    "\n",
    "    def _fit_predict_tree(self, x, y):\n",
    "        # Обучаем дерево и возвращаем его предикшн\n",
    "        tree = ...\n",
    "        # your code here\n",
    "        return self.gamma * self.learning_rate * tree.predict(x)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        x - np.array of shape (m, d)\n",
    "        OUTPUT:\n",
    "        y_pred - np.array of shape (m,)\n",
    "        \"\"\"\n",
    "        # Используем сохранённые деревья для расчёта агрегированного предикшна\n",
    "        # your code here\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте вашу реализацию на Boston dataset. Подберите оптимальные гиперпараметры, чтобы победить RandomForestRegressor как в обычном случае, так и при нахождении оптимального шага **(не меняйте параметры сида)**. При необходимости воспользуйтесь GridSearch. За это вы получите ещё 1 балл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(max_features=4, n_estimators=640, random_state=19052019)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19052019)\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозируем задержки самолётов (3 балла)\n",
    "\n",
    "Поработаем с задачей про задержки самолётов. На основании доступных данных о рейсе вам нужно определить, будет ли он задержан на 15 минут.\n",
    "Воспользуйтесь любыми методами градиентного бустинга {XGboost, catboost, LightGBM} и GridSearch для достижения результата. Получите 2 балла за преодоление порога roc_auc_score 0.72 и ещё 1 балл за преодоление порога 0.74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('flight_delays_train.csv')\n",
    "test = pd.read_csv('flight_delays_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Референс\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "X_train = train[['Distance', 'DepTime']].values\n",
    "y_train = train['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "X_test = test[['Distance', 'DepTime']].values\n",
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb_model.fit(X_train_part, y_train_part)\n",
    "roc_auc_score(y_valid, xgb_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Часть 2. Обучение без учителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Кластеризация (4 балла)\n",
    "\n",
    "Задача [кластеризации](https://en.wikipedia.org/wiki/Cluster_analysis) данных является одним из примеров задач обучения \"без учителя\". Она заключается в разбиении множества объектов на заданное число кластеров, при этом предполагается, что внутри одного кластера будут находиться похожие между собой объекты. Одним из примеров методов кластеризации является алгоритм [KMeans](https://en.wikipedia.org/wiki/K-means_clustering).\n",
    "\n",
    "### Выбор числа кластеров\n",
    "\n",
    "Для некоторых алгоритмов кластеризации число кластеров является гиперпараметром (например, в случае KMeans). Поэтому для выбора количества кластеров может быть испоьзован следующий подход: при фиксированной метрики качества для разного числа кластеров вычисляют кластеризацию и выбирают то значение, начиная с которого качество \"стабилизируется\".\n",
    "\n",
    "### Метрики качества\n",
    "\n",
    "Оценивание качества построенной кластеризации не всегда тривиальная задача, так как следует учитывать такие факты как:\n",
    " - объекты одного класса должны быть более похоже, чем объекты других кластеров, относительно некоторой заданной метрики похожести\n",
    " - метрика не должна учитывать абсолютные значения меток объектов, попавших в кластер (в случае, если истинные метоки известны)\n",
    "\n",
    "При выполнении задания для оценки качества получившейся кластеризации воспользуемся следующими метриками:\n",
    " - [Homogeneity и Completeness](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure) \n",
    " - [Adjusted Rand index](http://scikit-learn.org/stable/modules/clustering.html#adjusted-rand-index) \n",
    " - [Silhouette Coefficient](http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных [digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). Перед применением алгоритмов не забудьте перемешать изображения в случайном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризуйте изображения при помощи алгоритма [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), подобрав число кластеров для некоторой фиксированной метрики из указанных выше. Рассмотрите различные способы выбора начального приближения (параметр *init*). Оцените качество получившейся кластеризации используя все описанные выше метрики. Визуализируйте изображения, соответствующие центроидам лучшей кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "%pylab inline\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш вывод тут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clusters_centers(data, num_clusters, init0):\n",
    "    estimator = KMeans(init=init0, n_clusters=num_clusters)\n",
    "    estimator.fit(data)\n",
    "    \n",
    "    centers = estimator.cluster_centers_\n",
    "    for elem in centers:\n",
    "        elem = elem.reshape((8,8))\n",
    "        plt.imshow(elem, interpolation='none')\n",
    "        plt.show()\n",
    "        \n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш вывод тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не всегда бывает удобно работать с полной матрицей объект-признак, например, для случая визуализации данных. Можно применить метод уменьшения размерности *PCA*. Вот [здесь](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#example-manifold-plot-lle-digits-py) было показано сравнение различных способов сжатия размерности для проекции на плоскость. На изображениях видно, что некоторые преобразования дают неплохую картину и одинаковые цифры расположены близко друг к другу. Посмотрим, поможет ли это на практике.\n",
    " \n",
    "Примените преобразования [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) и [tSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) (для числа компонент 2 и 10) и сравните результаты с предыдущими. Нашелся ли метод кластеризации, превосходящий другие по всем метрикам? Являются ли все три метрики согласованными? Можете ли вы объяснить почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш вывод тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте несколько изображений, которые во всех случаях были отнесены к неправильному кластеру (объект назовем ошибочно отнесенным, если он имеет иную метку класса, нежели большая часть объектов в кластере). Можете ли вы пояснить почему так произошло?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш вывод тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Разделение изображения на семантические компоненты (4 балла)\n",
    "\n",
    "![RedPanda](http://imgur.com/6Aa52Lm.png)\n",
    "\n",
    "Алгоритмы кластеризации могут применяться в самых разных задачах. Например, в анализе изображений есть задача разделения изображения на семантические компоненты, которую можно решать в том числе с помощью алгоритмов кластеризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "image1 = imread(\"duck.jpg\")\n",
    "plt.imshow(image1)\n",
    "plt.show()\n",
    "image2 = imread(\"owls.jpg\")\n",
    "plt.imshow(image2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого изображения, используя кластеризацию KMeans, выделите компоненты, охарактеризовав каждый пиксель следующим образом: $\\psi_i = [\\lambda x_i, \\lambda y_i, r_i, g_i, b_i]$, где \n",
    "$x_i$ и $y_i$ — координаты пикселя, $r_i, g_i, b_i$ — его цвет, $\\lambda$ — параметр, выражающий важность пространственной связности перед цветовой похожестью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_components(image, lmbd, n_clusters):\n",
    "    #your code here\n",
    "    \n",
    "find_components(image1, 0.3, 3, 1)\n",
    "find_components(image2, 1.5, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте выделить сегменты при помощи [спектральной кластеризации](http://scikit-learn.org/stable/modules/clustering.html#spectral-clustering). Обратите внимание на [пример в sklearn](http://scikit-learn.org/0.16/auto_examples/cluster/plot_lena_segmentation.html). Для ускорения работы алгоритма рекомендуется привести изображение к серому цвету. При необходимости можно сжать изображения в 2 раза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage import color\n",
    "from sklearn.feature_extraction.image import img_to_graph\n",
    "from sklearn.cluster import spectral_clustering\n",
    "\n",
    "def spectral_segmentation(image, n_clusters, method, beta, eps, one_picture):\n",
    "    #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте результаты сегментации (аналогично рисунку выше) для обоих методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image11 = skimage.color.rgb2gray(image1)\n",
    "rows, cols = image1.shape[0], image1.shape[1]\n",
    "image11 = skimage.transform.resize(image11,(int(0.5*rows),int(0.5*cols)))\n",
    "\n",
    "image22 = skimage.color.rgb2gray(image2)\n",
    "rows, cols = image2.shape[0], image2.shape[1]\n",
    "image22 = skimage.transform.resize(image22,(int(0.5*rows),int(0.5*cols)))\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с параметрами алгоритмов. Сравните два подхода и сегментации, к которым они приводят.\n",
    "Для всех ли изображений в результате сегментации хорошо видны контуры объектов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш вывод тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
